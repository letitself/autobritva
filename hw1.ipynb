{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2\n",
        "!pip install summa\n",
        "!pip install rake-nltk\n",
        "!pip install yake\n",
        "!pip install python-rake"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKv3obb9oZq5",
        "outputId": "5617bbc6-e459-4db4-a020-d7e06485570d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 56.3 MB/s \n",
            "\u001b[?25hCollecting docopt>=0.6\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=04d63d295509d86438ff74d164406a1ba6eaf18b96404182c050bd0c031f1986\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting summa\n",
            "  Downloading summa-1.2.0.tar.gz (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.7/dist-packages (from summa) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy>=0.19->summa) (1.21.6)\n",
            "Building wheels for collected packages: summa\n",
            "  Building wheel for summa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for summa: filename=summa-1.2.0-py3-none-any.whl size=54410 sha256=48b409af7b593dcab9047e9bac857009f71a2c4d88b7427f8f55fd5c20bcf6fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/64/ac/7b443477588d365ef37ada30d456bdf5f07dc5be9f6324cb6e\n",
            "Successfully built summa\n",
            "Installing collected packages: summa\n",
            "Successfully installed summa-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rake-nltk\n",
            "  Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /usr/local/lib/python3.7/dist-packages (from rake-nltk) (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (1.2.0)\n",
            "Installing collected packages: rake-nltk\n",
            "Successfully installed rake-nltk-1.0.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yake\n",
            "  Downloading yake-0.4.8-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from yake) (1.21.6)\n",
            "Collecting jellyfish\n",
            "  Downloading jellyfish-0.9.0.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 59.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from yake) (2.6.3)\n",
            "Collecting segtok\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.7/dist-packages (from yake) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from yake) (0.8.10)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from segtok->yake) (2022.6.2)\n",
            "Building wheels for collected packages: jellyfish\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.9.0-cp37-cp37m-linux_x86_64.whl size=73990 sha256=6ccc8a28c56bc6629aecc83d3c0a9e688f5b5459f2b5e19376c970c7a523f9c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/99/4e/646ce766df0d070b0ef04db27aa11543e2767fda3075aec31b\n",
            "Successfully built jellyfish\n",
            "Installing collected packages: segtok, jellyfish, yake\n",
            "Successfully installed jellyfish-0.9.0 segtok-1.5.11 yake-0.4.8\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-rake\n",
            "  Downloading python_rake-1.5.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: python-rake\n",
            "Successfully installed python-rake-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импортнем библиотеки"
      ],
      "metadata": {
        "id": "ktJC9eOWHEJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from pymorphy2.tokenizers import simple_word_tokenize\n",
        "from gensim.summarization import keywords\n",
        "import summa\n",
        "from rake_nltk import Rake\n",
        "import RAKE\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import requests\n",
        "from unicodedata import normalize\n",
        "from nltk import everygrams\n",
        "from statistics import mean\n",
        "import yake\n",
        "from collections import Counter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KnhXtIloIvK",
        "outputId": "07a65855-4ed7-4e9d-8f48-925428fda585"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Не стал ничего выдумывать, взял рандомные статьи с хабра, а в качестве ключевых слов там есть теги, они и стали тегами, еще прибавил к ним свои ключевые слова которые считаю нужными"
      ],
      "metadata": {
        "id": "9XzganQRHGm1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zLGt5z1Nicb3"
      },
      "outputs": [],
      "source": [
        "texts = ['По информации нескольких источников СМИ, несколько сотен сотрудников отказались перейти на «хардкорный» режим Маска для создания Twitter 2.0 и ушли из компании. В их числе оказались многочисленные разработчики и инженеры, которые работали в Twitter более пяти лет. В рамках второй волны увольнений за последние две недели Twitter закрыла офисы компании до 21 ноября и отключила доступ по бейджам. По мнению экспертов, Маск и его команда оказались напуганы тем, что сотрудники массово решили уйти из компании. В отделе кадров не смогли оперативно выяснить, для каких сотрудников Twitter нужно отключить доступ к офисам компании, и решили заблокировать всех. Примечательно, что Twitter пока не деактивировала учётные записи сотрудников, которые решили публично уволиться. Маск и его команда собрали только список с ответами «Да» — сотрудников, которые сказали, что хотят быть частью Twitter 2.0. Руководство соцсети все ещё пытается понять, кто решил уйти из ключевых разработчиков и инженеров. Решившие остаться и те сотрудники Twitter, кто не хочет быть хардкорными, сообщили СМИ, что, Twitter скоро начнёт испытывать проблемы с работоспособностью платформы. По их мнению, ушли многие легендарные инженеры и команды разработчиков, которые сделали это место невероятным. «Twitter будет очень трудно оправиться от этого ухода сотрудников, независимо от того, насколько хардкорными будут оставшиеся работники», — пояснили СМИ источники внутри компании. После того, как крайний срок ответа Маску по хардкорности истёк, сотни сотрудников Twitter начали публиковать прощальные сообщения и салютовать смайликами в Slack, заявляя, что они отказались от ультиматума нового главы компании. «Я не нажимаю на кнопку», — написал один увольняющийся сотрудник в Slack. «Мои часы заканчиваются на Twitter 1.0. Я не хочу быть частью Twitter 2.0». По информации Washington Post, без инженеров остались ключевые команды, отвечавшие за критические системы и стабильность сервисов платформы. Источники Verge раскрыли, в полном составе ушла команда, поддерживающая ключевые системные библиотеки, которые использовали все разработчики, а без неё Twitter не сможет работать полноценно, как раньше. Из Twitter также ушли некоторые инженеры, оказывающие круглосуточную техподдержку внутренним отделам, а также часть команд, которые правили баги и предотвращали полное отключение сервисов в случае отказа облачных систем. 16 ноября Маск предоставил всем сотрудникам Twitter сутки на принятие решения: перейти на новый «хардкорный» режим и не жаловаться или покинуть компанию с выходным пособием. Маск в письме к сотрудникам пояснил, что для создания Twitter 2.0 компания должна быть чрезвычайно хардкорной уже сейчас. «Это означает долгие часы работы с высокой интенсивностью. Только исключительная работоспособность каждого будет считаться проходным баллом», — предупредил глава компании сотрудников. Маск пояснил, что новый Twitter будет в большей степени ориентирован на разработчиков и инженеров. А те, кто пишет «отличный код», будут иметь наибольшее влияние в компании. «Если вы уверены, что хотите стать частью нового Twitter, нажмите «Да» по ссылке ниже… Какое бы решение вы ни приняли, спасибо за ваши усилия, направленные на то, чтобы сделать Twitter успешным», — подытожил Маск. 15 ноября Маск в ручном режиме уволил разработчика приложения Twitter для Android с шестилетним стажем в компании из-за критики руководства. Инженер открыто защищал перед Маском свою команду и наработки, а также пояснил, почему есть проблемы в работе мобильного приложения, и что Маск не совсем правильно понимает ситуацию. По информации Platformer, Twitter уволила после этого ещё около 20 разработчиков, когда они раскритиковали текущие активные действия Маска во внутренней переписке в Slack. 5 ноября Маск уволил половину из 7500 сотрудников Twitter. После этого события создатель сервиса коротких сообщений и дважды бывший гендиректор Twitter Джек Дорси взял на себя ответственность за массовые увольнения в компании, устроенные Маском. По мнению Дорси, именно он виновен «в слишком быстром росте штата Twitter».', '15 человек, из них — один руководитель проекта, три фронта, два бэка, три аналитика, девопс. Симптомы обычные: процессы всем не нравятся, соседи — козлы, потому что не то и не так делают, а как нужно — не знают, ответственности ни на ком толком нет ни за что. Вроде бы когда-то это был настроенный конвейер, но теперь его куски — как будто в разных зданиях. Особо не заботятся о том, что было «до» и что будет «после». А если всё падает, то люди поднимают руки: «Я не виноват. Я не знаю, как поднять». Проект — внутренний банка, он нужен для улучшения работы внутри компании. Традиционных решений в кровавом энерпрайзе — два: нанять новую команду (но вгружать мидла на проект такой сложности — три-четыре месяца) или же оставить проект на поддержке, через два года найти ему замену, а команду тихо похоронить в подвале. Точнее, не так: те, кто плывет по течению и не заботится о карьере, остаются тихо сидеть «на пенсии», то есть в бесконечной поддержке проекта. А самые проактивные тут же перейдут в другие команды или другие компании. Почему процессы разваливались? На первый взгляд, потому, что была куча ненужных совещаний и встреч с теми, кого разработчики вообще не должны были видеть. Плюс местами странноватые KPI. Как это ни странно, но если психологически давить на разработчика пару лет, то ничем хорошим это не закончится. Руководство подразделения дало мне карт-бланш на исправления, и я начал разбираться, что же случилось. Заранее никак не понять. Нужно попробовать и посмотреть, насколько сама команда готова двигаться и меняться. В моём случае я верил, что те разработчики, которых я знал лично, готовы дальше бороться и за крутой продукт, и за то, чтобы им было правильно/приятно/эффективно работать. На любом этапе у меня была возможность признать, что команда скорее мертва, чем жива, и начать её «зачищать», то есть резать и нанимать новых людей. Все участники процесса это понимали, а также все понимали, что онбординг займёт немало времени: это внутрянка банка, и, кроме самого технического онбординга, есть ещё получение разных допусков, в частности, от обычной безопасности и ИБ. И потом ещё пара месяцев ушла бы просто на понимание интеграций и того, что и как там работает. Теперь — про меня. Девять лет я разрабатывал, из них пять — в банковской сфере. Бэк, фронт, потом — фуллстек, тимлид, руководитель разработки, теперь — техдир. Многое дерьмо, которое я повидал, — оно совсем даже не из книжек. Такое встречается только на практике. Это один из тех случаев, когда практика закончилась более-менее хорошо, и, возможно, вам этот опыт когда-нибудь пригодится. Вот вы новый руководитель некоей (любой) команды. Приходите и говорите, что вы ёжик и теперь будете жить с ними. Моделей вот в этом процессе я видел две: Капитан Америка и «серый кардинал». Капитан Америка приходит на работу и надевает костюм. Врывается «с ноги». Говорит: «Эй, я кэп, я тут. Давай будем работать». Замыкает всё или всех, но по очереди на себе. Где-то реально делает правильно. Он кэп. Он знает. Он в костюме. После этого он начинает потихоньку делегировать то, что замкнул до этого на себе. Дальше отходит и просто наблюдает. Кэп хорошо заходит, если ты, например, хардкорный джавист и пришёл лидить джавистов. Открываете так дверь с ноги и говорите: «Вы всё делаете неправильно. Сейчас я вас научу». У меня команда кросс-функциональная, поэтому чисто техскиллами я не мог давить. Нужно было сделать так, чтобы команда сама поняла, что не так, сама начала меняться и сама всё сделала правильно. Но поскольку до этого она этого не сделала, то им нужен кто-то, кто будет в этом помогать. Не пинать в нужную сторону, как Кэп, а именно консультировать и всё время задавать неудобные вопросы.Первое дело — знакомство. Сейчас это обычно зум-колл, руководитель проекта представляет вас и говорит: вот оно будет жить с нами. И все такие: ага, спасибо, сейчас чай допью. В переговорках есть ещё хоть какой-то шанс познакомиться ближе, но на удалёнке частая ошибка — разговаривать преимущественно со знакомыми в этот период. Не надо так делать, надо знакомиться. Поэтому первая задача — некий аудит. Я видел, когда руководитель так на конфколле познакомился, а через месяц вдруг в команду пришёл какой-то тип и спросил, кто он такой. Оказалось, это тестировщик вернулся из отпуска, а про него забыли. Это был тестировщик-сюрприз. Насчёт первого впечатления и остального париться в таких ситуациях не надо. Команде не до того, у них, скорее всего, какой-нибудь релиз горит. Они вас послушают, покивают, а через пять минут забудут имя. Лучше всего рассказать совсем мало про себя и послушать про человека. Важно показать каждому, что вы не «эффективный менеджер», а хоть чуть-чуть, но свой. И понимаете, в чём проблема. У нас уже на этой стадии стало понятно, что команда очень хочет перемен. Структура была «маленькие отряды»: разработчики недовольны разработчиками, тестировщики — разработчиками, фронты на ножах с бэками, РП вообще никем не удовлетворён. По впечатлениям команды он скорее эцилоп, который приходил бить палкой по ночам на ретро, чем помощник. Забегая вперёд — нет, он как раз пытался помочь, но начал не с процессов, а с разборов конкретных косяков. Дальше нужно понять, чем команда живёт и как. Не послушать про процессы, а пройти каждый. То есть ходить на все встречи вообще. Первое дело — знакомство. Сейчас это обычно зум-колл, руководитель проекта представляет вас и говорит: вот оно будет жить с нами. И все такие: ага, спасибо, сейчас чай допью. В переговорках есть ещё хоть какой-то шанс познакомиться ближе, но на удалёнке частая ошибка — разговаривать преимущественно со знакомыми в этот период. Не надо так делать, надо знакомиться. Поэтому первая задача — некий аудит. Я видел, когда руководитель так на конфколле познакомился, а через месяц вдруг в команду пришёл какой-то тип и спросил, кто он такой. Оказалось, это тестировщик вернулся из отпуска, а про него забыли. Это был тестировщик-сюрприз. Насчёт первого впечатления и остального париться в таких ситуациях не надо. Команде не до того, у них, скорее всего, какой-нибудь релиз горит. Они вас послушают, покивают, а через пять минут забудут имя. Лучше всего рассказать совсем мало про себя и послушать про человека. Важно показать каждому, что вы не «эффективный менеджер», а хоть чуть-чуть, но свой. И понимаете, в чём проблема. У нас уже на этой стадии стало понятно, что команда очень хочет перемен. Структура была «маленькие отряды»: разработчики недовольны разработчиками, тестировщики — разработчиками, фронты на ножах с бэками, РП вообще никем не удовлетворён. По впечатлениям команды он скорее эцилоп, который приходил бить палкой по ночам на ретро, чем помощник. Забегая вперёд — нет, он как раз пытался помочь, но начал не с процессов, а с разборов конкретных косяков. Дальше нужно понять, чем команда живёт и как. Не послушать про процессы, а пройти каждый. То есть ходить на все встречи вообще. На каждой встрече я записывал: Для чего эта встреча нужна: цели. Получилось ли на встрече этих целей добиться. Что мешает, если нет? Первое же дейли было больше похоже на перестрелку в Чикаго, когда обаятельные бандиты, всячески стараясь соблюдать вежливость, устроили бойню на складе алкоголя. То есть дейли прошло весело, дошло до сомнений в правильности монтажа рук в тело и так далее. В общем, это было что угодно, но не дейли. Потом — первое ретро. На нём как раз и делали дейли, потому что на дейли не хватило времени. Дальше надо было общаться с людьми. Руководство — это постоянно со всеми разговаривать. Хорошо, если вы умеете давать обратную связь, умеете хвалить людей и умеете слушать. Вот в модели «кардинала» следующий этап — как раз про «слушать». С каждым из участников команды нужно провести встречу один на один. Я приходил и говорил: «Товарищ Сеня, ты бэкендер. Расскажи, как ты работаешь?» Он должен рассказать всё от и до максимально детализированно. Вам надо из него всю эту информацию выудить, чтобы понять вообще, что он делает. Дальше надо из него вытащить жалобы. Новым людям всегда проще на что-то пожаловаться и понадеяться, что вы это исправите. Все жалобы надо тщательно записывать. Похвалы — тоже. Наверняка в команде что-то хорошо работает. Такое бывает редко, но бывает. Поэтому обязательно желательно знать, что работает хорошо. Дальше — пожелания. «Сеня, опять-таки расскажи, чего бы тебе хотелось». Сеня — айтишник, поэтому всегда первой фразой говорит: «Хочу денег». Вы: «Давай что-нибудь поинтереснее». Дальше, может быть, он расскажет, а может быть, и нет. На этих же встречах надо выписать вообще все используемые инструменты и отношение к ним. Бывало, что команда должна работать в Джире, но она просто бесит всех без исключения, и даже есть идеи, на что её поменять. Отношение к инструментам — это всегда важно. С каждого из участников команды важно собрать, как он работает: либо нарисовать процесс в виде какой-то импровизированной блок-схемы, либо просто переписать по пунктам, что происходит. Единственный момент — лучше сразу это рисовать в каком-то общедоступном инструменте, чтобы все видели эту схему позже и могли в неё что-то дорисовывать при желании. Итак, на этом этапе я сходил на десяток бесполезных встреч, поработал аналитиком, переписал инструменты и первично понял, где и что болит. Анамнез собран. Когда общая схема того, как работает команда, нарисована, а она нарисована уже на прошлом шаге, потому что вы же собрали с каждого, как он работает, — пора в ней разбираться всем. У нас проблема была, например, в том, что схема не мержилась без конфликтов. То есть были люди с разным мнением по поводу того, как и что работает. В смысле что Сеня знает, как ставится задача, и Вася знает, но только процессы у них сильно разные. А ещё интереснее это происходит на тех стыках, где Вася ставит задачу Сене. Сначала мы собрали все места, где показания расходились, и договорились, как же они должны работать. Потом начали проговаривать вроде бы очевидные вещи. Прямо шли по схеме и обсуждали каждый процесс: вот аналитики принимают требования, заводят в Джиру, на выходе — то-то и с такими-то свойствами. Записали. Все согласны? Нет, не все: у кого-то — дополнение, у кого-то — замечание. Ещё раз прогоняем процесс с учётом этого, записываем, вносим в схему. Теперь так? Если нет — снова и снова, пока не устроит всех участников. Если в процессе всплывает проблема, например, «аналитики не согласовывают с разработчиками» или «тестировщики заводят хреновые баг-репорты», то записываем отдельно, а потом возвращаемся. Дальше мы прошли весь процесс от бизнес-требований до прода. Появилась схема, где всё досконально описано: кто какой артефакт отдаёт, что у кого на входе и на выходе. Поскольку я не кэп, команда решала это сама. Я просто людей усаживал и говорил: «А теперь деритесь!» По каждому процессу, пока не приходили к консенсусу, обсуждение не заканчивали. Выход этого шага — документ, который описывает работу команды. Плохо работающий, но понятный всем процесс, — на самом деле это уже начало эволюции. По крайней мере, все понимают, чего и от кого ждать, можно ли уже злиться или работа сделана правильно. Самое главное на этом этапе — дать понятные правила игры, и это они. А вот дальше нужно переходить к изменениям. У нас уже накопились список жалоб, список похвал, мы понимаем отношение друг друга к процессу. Выбираем точку, которая болит сильнее всего, и лечим её. Но при этом не ломаем того, что уже хорошо. Суть такая же, как при ревью процесса: каждый участник или подписывается, что всё правильно, и принимает процесс, или предлагает изменения. Не всегда эти изменения нужны: например, кто-то может прийти и сказать, что вот такой-то шаг лишний, потому что он замедляет процесс. Но может оказаться, что этот шаг вообще-то завязан на информационную безопасность и без него нельзя. То есть надо либо просто разобраться, откуда у чего растут ноги и почему люди так делают в принципе, либо понять, какие есть альтернативы. Чаще приносят реально боль, которую можно исправить. Вот кто-то сказал, что у нас очень долгое планирование. Садимся и обсуждаем. Аналитики рассказывают, от чего зависит срок. Оказывается, им не хватает части данных, они их мучительно получают. Просим заказчика предоставлять эти данные сразу — и проблема решается. Точнее, переезжает к заказчику на самом деле, но он с этим согласен. Повторяем итерации «согласен», «есть комментарий» или «не согласен» до тех пор, пока не пройдём весь процесс.В итоге получается процесс, который понятен всем, и под каждым пунктом все подписались. Это важно, потому что, когда люди подписываются под чем-то, они чувствуют какую-то персональную ответственность. Когда разработчик сказал: «Я согласен с тем, что теперь буду писать комменты на английском языке» — это вы поговорили. А когда вы при этом записали такое обязательство — это уже нечто более существенное. Так принято. Это документация. Это часть работы команды. Важно, чтобы во всём этом каждый член вашей команды поучаствовал, чтобы каждый мог сказать своё «фи». Люди не должны чувствовать, что к ним пришли и что-то навязали. Они сами — авторы процесса. Они сами сделали и подписались под тем, как они теперь живут и работают. Больше всего на этом этапе я боялся невовлечённости. Если бы глаза не горели, изменений никто бы не хотел и команда не решилась бы пересматривать процесс — пришлось бы «зачищать». Но у нас согласование процесса стало точкой невозврата. На выходе — целый документ, который можно использовать. Если приходит кто-то новенький — можно показывать его уже как онбординг и регламенты. Если приходит бизнес и спрашивает: «А что вы вообще делаете?» (у меня такое часто было) — есть ответ. Вроде работают 20 человек, а вроде не работают, результата мало. Бизнесу сократить бы издержки, то есть он ищет кого-то, кого можно перевести из команды в другое место или уволить. А вы в ответ показываете документ и говорите: вот каждая роль. На практике, кстати, хорошо помогает подсветить проблемы. У меня зачастую бизнес был автором задержек. И вроде как бизнес пришёл жаловаться на неэффективность, а уходит с новыми задачами ) У нас многие проблемы были из-за непрозрачности внутри команды. Например, РП постоянно приходил и спрашивал: «Ты сделал? Ты сделал?» Это было похоже на постоянное стояние над душой и мало кому нравилось. Решили отобрать у него вообще необходимость задавать такие вопросы, сделали дашборд с понятными метками. А меток не было, потому что не было Джиры, а Джиры не было, потому что не договорились, что работаем по процессу с ней, только с ней и по определённым правилам. А умирать всё начало при переходе на удалёнку, когда в курилке уже никто не ловился и коммуникации стали асинхронными. Починили, почувствовали победу. А ещё разработчики попросили от них отстать. Это наследие тех самых ненужных встреч, которые тоже как грибы выросли после пандемии. Менеджеру дёшево всех выдернуть, разработчикам дорого это слушать. Ввели часы тишины. Общее правило такое: если кто-то работает мозгами, а не руками, то трогать его в эти моменты нельзя. То есть пока разработчик разрабатывает — НЕ ВЛЕЗАЙ, УБЬЁТ! Разработчики увели четыре часа в день в тишину, а остальные стали сильно внимательнее относиться к их времени.', 'После новостей, что на заводе «Москвич» начинают производить одноименные электромобили, мне стало интересно, что вообще происходит с электромобилями в России. У нас есть китайско-московские «москвичи», на «Камазе» тоже планируют собирать что-то похожее (и даже были довольно интересные прототипы), а что еще? А сколько их вообще? Кто это покупает? И есть ли в этом какой-то смысл? В Газпромбанке есть «Центр экономического прогнозирования», который занимается макроэкономической и отраслевой аналитикой. Я насел на их старшего аналитика Михаила Ведищева, забросал его вопросами и собрал в кучу ответы. Под катом — анализ текущей ситуации, прогнозы и некоторое количество зубодробительной статистики. Сразу оговорюсь, все данные, которые тут приведены — за первое полугодие 2022 года. Сколько вообще электромобилей покупают в России? В первом полугодии было куплено 5,8 тыс. электрокаров. Это больше, чем за первую половину 2021 года. По прогнозам, по итогам года будет приобретено около 14 тысяч машин. Это сопоставимо, например, с общими продажами Audi в РФ в прошлом году. А если сравнить с мало представленным на нашем рынке Suzuki, то «электричек» было продано в полтора раза больше. Много это или мало? Всего у нас зарегистрировано 18,7 тысяч электромашин. Кажется, что много. Но если сравнить с общим количеством автомобилей, то их доля в автопарке (тут напомним, что говорим о данных на конец первого полугодия 2022 г.) будет мизерной — около 0,04%. Почти две трети (65,8%) всех электрокаров — это Nissan Leaf (более 12 тыс. шт.). На втором месте, с большим отставанием, располагается Tesla (2,4 тыс. шт.), на которую приходится около 13%. Третью строчку занимает Porsche (837 шт.). В ТОП-5 вошли еще Audi (718 шт.) и Mitsubishi (497 шт.). По сути, весь парк можно разделить на дорогие электрокары и бюджетные Nissan Leaf. Есть вероятность, что в ближайшие годы сегмент массового доступного электромобиля в России пополнится такой моделью, как Chevrolet Volt. Примерно каждый седьмой легковой автомобиль на электротяге зарегистрирован в Москве, в которой их 2,8 тыс. экземпляров. На втором месте по количеству электроавто у населения — Приморский край (1,7 тыс. шт.), на третьем — Иркутская область (1,6 тыс. шт.). Откуда берутся электроавтомобили? В прошлом году в России было приобретено 2000 новых электромашин. А по итогу этого ожидается больше трех тысяч. Примерно половина из всего ввозимого — Tesla. А около четверти рынка занимают немецкие премиальные бренды — Audi и Porsche. Ни Tesla, ни многие другие производители в Россию свою продукцию официально не поставляют и почти все поставки новых электроавто — «серые» или станут таковыми в ближайшее время. А вот подержанные продаются гораздо лучше: в 2021 году было продано около 9 тысяч штук, а по итогам этого ожидается около 11 000. Чуть больше половины — свежепривезенные, а остальное — перепроданные уже тут. При этом все машины, которые приезжают к нам из-за рубежа, ввозят частники: физлицам возить их выгодней из-за сборов. Тут все стандартно: богатые и не очень. Одни покупают премиальные «электрички» с большим запасом хода в качестве основного автомобиля, другие берут подержанный Nissan Leaf, чтобы экономить на топливе. При этом, как правило, Leaf берут вторым автомобилем в семью. Как это поняли? Все просто: значительная часть «лифов» обитает в Сибири и на Дальнем Востоке. В довольно «автомобилизированных» регионах. Машины эти, как правило, не новые, а значит, до «паспортного» пробега на одной зарядке им далеко. Плюсуем сюда расстояния между населенными пунктами, на поездку между которыми не хватит заряда даже нового аккумулятора и делаем логичный вывод: их паттерн использования — вторая машина для поездок по городу. А вот с новым авто все не так просто. Есть расчет компании Vygon Consulting, которая сравнила полную стоимость владения новым электромобилем со стоимостью владения новым авто с ДВС. Из-за изначально высокой цены «электрички» стоимость владения «обычной» машиной при небольших годовых пробегах может оказаться даже меньше. Но опять же, надо помнить, что такой расчет не имеет смысла, когда речь заходит о б/у: при выборе между Leaf за 600-700 тыс. ₽, и двухлетней бюджетной моделью с ДВС низкие удельные расходы на содержание будут иметь совершенно другой вес, чем указано в расчете. В России анонсируются проекты по выпуску электроавтомобилей, основанные на «бейдж-инжиниринге». 4 сентября отечественная компания Evolute официально представила три серийные модели электромобилей: Evolute I-PRO, Evolute I-JOY и Evolute I-JET на базе китайских Dongfeng. Первые машины уже появились в продаже. Столичный автомобильный завод «Москвич» тоже представил свой модельный ряд. Изначально не сообщали, на базе чего их будут производить, но на изображениях можно было угадать китайский JAC E-S4. Кроме этого, «Москвич» начал работу по созданию собственной платформы электромобилей. По замыслу компании, в будущем предприятие сможет производить электрокары, используя основные компоненты российского производства, включая аккумуляторы, электродвигатель и систему безопасности. Созданием электрокаров намерен заняться оборонный холдинг «Алмаз-Антей». Обуховский завод из Санкт-Петербурга разработал прототип кроссовера E-Neva. Ориентировочный срок начала производства — 2024 год. Еще можно вспомнить о проекте КАМА. Прототип субкомпактвэна даже успели протестировать некоторые автоблогеры, но из-за ухода зарубежных партнеров по инжинирингу, судьба «камы» не очень понятна: по последним данным изготовление пилотной серии ожидается не раньше 2024 года. Вообще, КАМА —довольно спорный проект. У субкомпактвэнов крайне низкая доля на нашем рынке — их практически нет. И как пойдут их продажи, учитывая, что у нас больше ценят седаны или кроссоверы, тоже не ясно.', 'У нас в Газпромбанке сложилась довольно интересная ситуация. Банк относительно недавно начал активно работать с розницей, которая как локомотив начала тянуть все внутрибанковское IT и менять характер работы всех подразделений. Одна из главных наших проблем (впрочем, как и у многих) — долгие релизы, низкое качество кода, недоступность и нестабильность систем на тестовых полигонах. Но главное — интеграционные релизы. Когда несколько команд одновременно пытаются зарелизить свои доработки, нужно много времени и средств, чтобы синхронизировать всех. При этом каждый привносит новые баги, все начинают бегать кругами, спотыкаться, фиксить, перенакатывать… В итоге качество продукта низкое, а пользователь смотрит на это все с недоумением. Как с этим всем бороться? Мы пришли к такому рецепту: избавиться от интеграционных релизов. Вообще. Собрать автономные, кросс-функциональные команды, каждая из которых будет выполнять свою задачу, не толкаясь локтями с другими. Для этого перепилить пайплайн, повысить инженерную культуру, ввести стандарты и так далее. Подробнее — под катом. Для начала мы обратили внимание на то, как у нас устроено тестирование. О том, как и в каком порядке должны быть сгруппированы тесты написал еще Майк Кон в книге «Scrum: гибкая разработка ПО» (Succeeding With Agile. Software Development Using Scrum). Он предложил хорошую абстракцию: пирамиду тестирования. Она в простом и понятном виде демонстрирует как правильно должен быть организован процесс разработки. По Кону в основании пирамиды должны быть быстрые и дешевые юнит-тесты, с помощью которых быстро закрывается максимальное количество дефектов, выходящих из разработки. Выше – компонентные и интеграционные тесты. И на самой вершине небольшое количество самых дорогих тестов — ручных. Главное: большинство багов должно закрываться тестами на самом раннем этапе.Как оказалось, наша пирамида выглядит не совсем так. Порядок в ней правильный, но сама она стоит вверх ногами. В нашем варианте большая часть дефектов выявлялась и устранялась на позднем этапе разработки, что дороже, занимает больше времени и просто неэффективно.Чтобы не тратить время, деньги и силы на исправление дефектов после этапа разработки, мы начали сдвигать влево этап тестирования, чтобы он приходился на более ранние этапы жизненного цикла продукта. Для начала «включили» Quality Gate на покрытие юнит-тестами в каждой системе и в каждом сервисе, которые используют наш пайплайн. Нужно было чтобы каждая команда по мере развития своего продукта на регулярной основе пилила «юниты». Их создание должно войти в привычку, как чистка зубов по утрам. Если вы еще этот этап не прошли, готовьтесь — будет много БОЛИ. Всем некогда, всем надо срочно, быстро и вот прямо сейчас, а тесты мешают. Но результат стоит того. Уже через месяц аналитика показала, что количество функциональных дефектов на этапе тестирования снизилось вдвое. Да, срез пока довольно маленький: покрытие тестами розничных продуктов пока около 40%, но мы планомерно идем к увеличению покрытия. Кроме этого в ворота добавили статический анализ кода, проверки на уязвимость, а в скором  времени добавим контрактные и импакт-тесты. Вторые «ворота» ориентированы непосредственно на процесс деплоя. Они включает в себя базовые проверки кода на жизнеспособность — Health Check. А после этого, в зависимости от того, какие ресурсы есть у команды, прогоняются ручные и автоматизированные тесты.Семантическое версионирование, стандарты которого мы хотим использовать, влияет на производство косвенно. Но это важный шаг в налаживании взаимодействия как между самими командами, так и между разработкой и потребителем. В этой концепции всего три постулата, но благодаря им можно выстроить выпуск релизов без выпуска новых версий зависимых пакетов. Если вы еще не используете его, настоятельно рекомендуем к прочтению. Этот стандарт описывает обязательства, которых надо придерживаться при реализации взаимодействия сервисов и команд между собой. Если сформулировать совсем коротко: сохраняйте обратную совместимость при изменении сервисов.Номера версий должны четко соответствовать стандарту. Чтобы соблюдать SemVer-правила, перед деплоем в Nexus это соответствие дополнительно проверяется скриптами (на Python). Ничего задеплоить не выйдет до тех пор, пока все не будет по правилам. Номера версий должны четко соответствовать стандарту. Чтобы соблюдать SemVer-правила, перед деплоем это соответствие дополнительно проверяется скриптами (на Python). Ничего задеплоить не выйдет до тех пор, пока все не будет по правилам. Что бывает если на это забить? Некая компания выпускает минорный апдейт некоего продукта. Некий разработчик смотрит на набор фичей, читает описание релиза и решает, что все это ему надо.  Ставит обновление. Все падает. Начинается головная боль: надо разобраться что произошло, пофиксить, откатить все обратно, предпринять меры, чтобы такое не повторилось. В зависимости от того, что именно обновлялось и как именно упало, голова может болеть от месяца до полугода. Тут можно вспомнить Apple. Компания любит своих пользователей, любит продавать им крутые продукты, но при этом совершенно ненавидит разработчиков. Когда выходят обновления инструментов, iOS и MacOS, то каждый раз (по нескольку раз за год) ломается основная среда разработки — Xcode. Даже после минорных обновлений производство может встать из-за того, что приложения перестают собираться.Еще одна важная история — Feature Toggle. Мартин Фаулер в своей статье описывает четыре типа тоглов. Самый базовый и основной для нас сейчас — тоглы релиза, которые позволяют выключить не готовый функционал. Если нужно выпустить срочный патч, но при этом мы работаем над новой фичей, то гораздо проще залить на прод все разом, выключив не готовое. Так мы избежим последующей проблем слияния новых фичей и патчей и обезопасим себя от раскатки на прод неготового функционала. Плюс к этому, разработку можно вести более гибко: когда несколько команд работают над какой-то фичей, то часть каждой можно выкатывать в прод в выключенном состоянии. После того как соберутся все куски, фичу можно либо сразу включить, либо допатчить перед этим в (опять же в нерабочем состоянии). Еще один тип — тоглы сопровождения. Они помогают обеспечить плавную раскатку функциональности. С их помощью можно, например, включать функции в зависимости от географического положения пользователя. Таким образом можно раскатать новые фичи на 1%, проверить, что у них все работает нормально и затем плавно доводить этот показатель до 100%. Тоглы прав доступа. В них нам важна возможность сегментирование функциональности по группам. Определенный клиент увидит только то, что предназначено конкретно для него (примеры групп: обычный клиент, премиум, студент, пенсионер и т.п). Последний тип тоглов — A/B-тесты — самый интересный с точки зрения бизнеса. С их помощью можно создать несколько вариантов одной фичи и раскатать каждый на определенную группу/количество пользователей. А затем посмотреть, какой принес большую конверсию и в автоматическом режиме выпустить его уже на всех. Еще одна проблема, которую нужно решить — наши тестовые системы не унифицированы. При накатах обновлений не соблюдается обратная совместимость, конфиги иногда правятся руками и все это приводит к недоступности систем и проблемам в тестировании. Часто, когда команде нужен тестовый полигон, он оказывается заблокирован тестированием или недоступностью смежных систем. Это, безусловно, боль. Но тут важно не пойти у нее на поводу: командам хочется новых полигонов, где будут жить какие-то системы каких-то версий, где все будет прекрасно и удобно тестировать. При этом мало кого волнуют проблемы обновления этих полигонов, поддержания их в актуальном состоянии и обеспечения доступности. Масштабирование — простой выход, но выход в никуда. Такой подход приведет не к решению проблем, а к их преумножению (помните про контроль версий?). Поэтому мы приняли стратегическое решение планомерно уменьшать количество тестовых сред до минимально необходимого уровня — одной. И сейчас прикладываем усилия, чтобы на этом полигоне все системы были доступны, чтобы все накатываемые обновления сохраняли обратную совместимость, и чтобы в случае проблем на хелсчеках все безопасно откатывалось на предыдущую версию.']\n",
        "key_w = [['Маск', 'Twitter', 'покупка', 'боты', 'соцсеть', 'сервис', 'микроблог', 'Илон', 'Маск', 'продажа', 'IT-компания', 'инвестор', 'подписка', 'верификация', 'устройство', 'смартфон', 'твитер', 'разработка', 'команда'], ['проект', 'разработка', 'банк', 'команда', 'процесс', 'задача', 'проверка', 'ревью', 'коллега', 'бизнес'], ['электромобили', 'транспорт', 'аналитика', 'автомобили', 'электрокары', 'электрокары в россии', 'экология'], ['разработка', 'devops', 'технологии', 'оптимизация', 'банк', 'IT', 'програмное обеспечение', 'по', 'этапы']]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Лемматизация ключевых слов и текстов\n"
      ],
      "metadata": {
        "id": "fqhbIvjLpTE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = MorphAnalyzer()\n",
        "def normalize_text(text):\n",
        "    lemmas = []\n",
        "    for t in simple_word_tokenize(text):\n",
        "        lemmas.append(m.parse(t)[0].normal_form)\n",
        "    return ' '.join(lemmas)\n",
        "\n",
        "corpus = [normalize_text(text) for text in texts]\n",
        "key_w = [set([normalize_text(k) for k in kw]) for kw in key_w]"
      ],
      "metadata": {
        "id": "ICxVZZYQoMAd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Количество токенов ниже"
      ],
      "metadata": {
        "id": "6TgPdpUTHZZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = 0\n",
        "for text in corpus[:10]:\n",
        "    l += len(text.split())\n",
        "print(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj47tDd9podZ",
        "outputId": "0aa2347e-9898-4d06-943d-02f04bc26d00"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "выделяем ключевые слова методами  text-rank rake и yake"
      ],
      "metadata": {
        "id": "b2Kt-ZwWHtr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop = stopwords.words('russian')\n",
        "tr_kw = [set([i[0] for i in summa.keywords.keywords(text, ratio=0.1, language='russian', additional_stopwords=stop, scores=True)]) for text in corpus]"
      ],
      "metadata": {
        "id": "Y62aTTAnp3Nd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rake = RAKE.Rake(stop)\n",
        "rake_kw = [set([i[0] for i in rake.run(text, minFrequency=1, maxWords=3) if i[1] > 0]) for text in corpus]"
      ],
      "metadata": {
        "id": "Zqzs8lGqpz0O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yk = yake.KeywordExtractor(lan='ru', n=1)#, dedupLim=deduplication_thresold, dedupFunc=deduplication_algo, windowsSize=windowSize)\n",
        "yake_kw = [set([i[0] for i in yk.extract_keywords(text)]) for text in corpus]"
      ],
      "metadata": {
        "id": "aS_Nj138qh98"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получим теги (шаблон для фильтрации)"
      ],
      "metadata": {
        "id": "SrP_Zk4tIRDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tags(kwds):\n",
        "    kws_pos = []\n",
        "    voc = []\n",
        "    for i in kwds:\n",
        "        ipos = []\n",
        "        for k in i:\n",
        "            kpos = []\n",
        "            for word in k.split(' '):\n",
        "                ps = str(m.parse(word)[0].tag.POS)\n",
        "                if ps == 'None':\n",
        "                    ps = str(m.parse(word)[0].tag)\n",
        "                kpos.append(ps)\n",
        "            ipos.append((k, kpos))\n",
        "            voc.append(' '.join(kpos))\n",
        "        kws_pos.append(ipos)\n",
        "    return kws_pos, Counter(voc)\n",
        "\n",
        "key_w_pos = get_tags(key_w)\n",
        "rake_pos = get_tags(rake_kw)\n",
        "tr_pos = get_tags(tr_kw)\n",
        "yake_pos = get_tags(yake_kw)"
      ],
      "metadata": {
        "id": "cu3A4V7Qqju1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_w_pos[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKi03Dl5qpNc",
        "outputId": "3a4197a9-f45c-4484-b1bc-df12e928156f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'NOUN': 37,\n",
              "         'LATN': 3,\n",
              "         'INFN': 1,\n",
              "         'NOUN PREP NOUN': 1,\n",
              "         'PREP': 1,\n",
              "         'ADJF NOUN': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ФильтрацияЁ"
      ],
      "metadata": {
        "id": "HNtN9YiNJrHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_kw(key_w_pos, templ):\n",
        "    fil_art = []\n",
        "    for art in key_w_pos[0]:\n",
        "        fil_k = []\n",
        "        for k in art:\n",
        "            if k[1] == templ:\n",
        "                fil_k.append(k[0])\n",
        "        fil_art.append(set(fil_k))\n",
        "    return fil_art"
      ],
      "metadata": {
        "id": "H3y7-LbrqxZq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подсчет метрик "
      ],
      "metadata": {
        "id": "CZZQ2oojJtoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_metrics(pred_kws, name, filt=''):\n",
        "    if filt != '':\n",
        "        pred_kws = filter_kw(pred_kws, filt)\n",
        "        true_kws = filter_kw(key_w_pos, filt)\n",
        "    else:\n",
        "        true_kws = key_w\n",
        "    precision = [len(kw & pred_kw)/len(pred_kw) if len(pred_kw) != 0 else 0 for kw, pred_kw in zip(true_kws, pred_kws) if len(kw) != 0]\n",
        "    recall = [len(kw & pred_kw)/len(kw) for kw, pred_kw in zip(true_kws, pred_kws) if len(kw) != 0]\n",
        "    fscore = [2*pr*rcl/(pr + rcl)  if pr + rcl != 0 else 0 for pr, rcl in zip(precision, recall)]\n",
        "    if mean(recall) + mean(fscore) + mean(precision) != 0:\n",
        "        print(name + ' ' + ' '.join(filt))\n",
        "        if filt == '':\n",
        "            print('\\n'.join(['keywords: ' + ', '.join(true_k) + '\\nound: ' + ', '.join(true_k & pred_k) for true_k, pred_k in zip(true_kws, pred_kws)]))\n",
        "        print('precision: ' + str(mean(precision)) +'\\nrecall: ' + str(mean(recall)) + '\\nf-score: ' + str(mean(fscore)) + '\\n')"
      ],
      "metadata": {
        "id": "lCfnmk7lrJi1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "rake - много мусора в следствии снижается точность да и полнота не оч, кароче по всем метрикам провал в сравнении с остальными\n",
        "textrank - лучше точность чем у раке но полнота все еще не оч но вот фскор тоже подрос и значительно\n",
        "yake - лучшие результаты по всем параметрам, ставлю лайк"
      ],
      "metadata": {
        "id": "ctfkEG09Khu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calc_metrics(rake_kw, 'rake')\n",
        "calc_metrics(tr_kw, 'textRank')\n",
        "calc_metrics(yake_kw, 'yake')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gpb9wiNrRpb",
        "outputId": "677f5ccd-240a-4df0-9570-08623a3d4859"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rake \n",
            "keywords: верификация, смартфон, команда, покупка, продажа, илона, микроблог, it-компания, устройство, бот, twitter, маск, сервис, подписка, твитер, соцсеть, разработка, инвестор\n",
            "ound: twitter, маск\n",
            "keywords: банк, разработка, задача, команда, проект, проверка, коллега, процесс, ревить, бизнес\n",
            "ound: проект, процесс, команда\n",
            "keywords: электрокар, аналитика, электрокар в россия, автомобиль, электромобиль, транспорт, экология\n",
            "ound: электрокар, электромобиль\n",
            "keywords: банк, технология, по, devops, этап, оптимизация, програмный обеспечение, разработка, it\n",
            "ound: разработка, этап\n",
            "precision: 0.010520194879730944\n",
            "recall: 0.22976190476190475\n",
            "f-score: 0.01939017150124294\n",
            "\n",
            "textRank \n",
            "keywords: верификация, смартфон, команда, покупка, продажа, илона, микроблог, it-компания, устройство, бот, twitter, маск, сервис, подписка, твитер, соцсеть, разработка, инвестор\n",
            "ound: сервис, twitter, маск, команда\n",
            "keywords: банк, разработка, задача, команда, проект, проверка, коллега, процесс, ревить, бизнес\n",
            "ound: бизнес\n",
            "keywords: электрокар, аналитика, электрокар в россия, автомобиль, электромобиль, транспорт, экология\n",
            "ound: электрокар, аналитика, электромобиль\n",
            "keywords: банк, технология, по, devops, этап, оптимизация, програмный обеспечение, разработка, it\n",
            "ound: разработка, этап\n",
            "precision: 0.08154225267460032\n",
            "recall: 0.24325396825396825\n",
            "f-score: 0.11326310782832523\n",
            "\n",
            "yake \n",
            "keywords: верификация, смартфон, команда, покупка, продажа, илона, микроблог, it-компания, устройство, бот, twitter, маск, сервис, подписка, твитер, соцсеть, разработка, инвестор\n",
            "ound: twitter, маск, команда\n",
            "keywords: банк, разработка, задача, команда, проект, проверка, коллега, процесс, ревить, бизнес\n",
            "ound: проект, процесс, команда\n",
            "keywords: электрокар, аналитика, электрокар в россия, автомобиль, электромобиль, транспорт, экология\n",
            "ound: электрокар, автомобиль, электромобиль\n",
            "keywords: банк, технология, по, devops, этап, оптимизация, програмный обеспечение, разработка, it\n",
            "ound: разработка, этап\n",
            "precision: 0.1375\n",
            "recall: 0.27936507936507937\n",
            "f-score: 0.17951199838677154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавление фильтрации очевидно улучшило результаты работы"
      ],
      "metadata": {
        "id": "eInpWSJLMBpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for meth in [(rake_pos, 'rake'), (tr_pos, 'textrank'), (yake_pos, 'Yyake')]:\n",
        "    for filt in key_w_pos[1]:\n",
        "        calc_metrics(*meth, filt.split(' '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtpcWo2yrcgt",
        "outputId": "2236b3cf-6e01-4e5f-a174-77958e3858cd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rake NOUN\n",
            "precision: 0.05080784225521068\n",
            "recall: 0.28137254901960784\n",
            "f-score: 0.07083583099801685\n",
            "\n",
            "rake LATN\n",
            "precision: 0.16666666666666666\n",
            "recall: 0.5\n",
            "f-score: 0.25\n",
            "\n",
            "textrank NOUN\n",
            "precision: 0.16438953203659085\n",
            "recall: 0.2968954248366013\n",
            "f-score: 0.19021110468478888\n",
            "\n",
            "textrank LATN\n",
            "precision: 0.5\n",
            "recall: 0.5\n",
            "f-score: 0.5\n",
            "\n",
            "Yyake NOUN\n",
            "precision: 0.23663003663003662\n",
            "recall: 0.3377450980392157\n",
            "f-score: 0.25603070175438597\n",
            "\n",
            "Yyake LATN\n",
            "precision: 0.25\n",
            "recall: 0.5\n",
            "f-score: 0.3333333333333333\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Решение проблем: придумать что делать с синонимами, улучшить морф разметку в частности для всяких брендов у которых разные названия всплывают в транслитерациях и т.п"
      ],
      "metadata": {
        "id": "-B8g_EMXMOCu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dG8Y1Avdrk38"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}